{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T13:09:28.391710Z",
     "start_time": "2025-05-14T13:09:20.863719Z"
    }
   },
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from src.process import create_image_view\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from src.AnonymizationInference import AnonymizationInference\n",
    "import os\n",
    "from src.evaluate import count_all_layoutlm_metrics, count_std\n",
    "from src.config import funsd_label_list\n",
    "\n",
    "\n",
    "def get_layoutlm_predictions(\n",
    "            inference, images, path_to_image, path_to_gt_labeled_images, labels_saving_path, image_views_path, path_to_gt_labels=None,\n",
    "    ):\n",
    "        for image in tqdm(images):\n",
    "\n",
    "            if not image.endswith(\".png\"):\n",
    "                continue\n",
    "\n",
    "            image_path = os.path.join(path_to_image, image)\n",
    "\n",
    "            if path_to_gt_labels:\n",
    "                with open(os.path.join(path_to_gt_labels, image.replace(\".png\", \".json\"))) as f:\n",
    "                    gt_labels = json.load(f)\n",
    "                words = gt_labels[\"tokens\"]\n",
    "                boxes = gt_labels[\"bboxes\"]\n",
    "                \n",
    "                predictions = inference.predict(image_path, words, boxes)\n",
    "            else:\n",
    "                predictions = inference.predict(image_path)\n",
    "            \n",
    "            img_with_pred_bboxes = inference.draw_bboxes(image_path, predictions)\n",
    "            img_with_gt_bboxes = Image.open(os.path.join(path_to_gt_labeled_images, image))\n",
    "            create_image_view(img_with_gt_bboxes, img_with_pred_bboxes, f\"{image_views_path}/{image}\")\n",
    "            label_name = image.replace(\".png\", \".json\")\n",
    "            with open(f\"{labels_saving_path}/{label_name}\", \"w\") as f:\n",
    "                json.dump(predictions, f, indent=4)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting predictions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T12:07:15.829139Z",
     "start_time": "2025-05-14T12:07:15.811684Z"
    }
   },
   "source": [
    "# weights of LayoutLM fine-tuned on SAND\n",
    "layoutlm_model_name = \"layoutlm_best\"\n",
    "# weights of LayoutLM fine-tuned on FATURA-PII-Train (80 docs)\n",
    "fatura_raw_model_name = \"fatura_raw\"\n",
    "\n",
    "# models\n",
    "detection_model=\"fast_base\"\n",
    "recognition_model=\"master\"\n",
    "ocr_model = f\"{detection_model}_{recognition_model}\"\n",
    "layoutlm_model = \"best_finetuned\"\n",
    "lm_model_weights = f\"weights/{layoutlm_model_name}\"\n",
    "fatura_model_weights = f\"weights/{fatura_raw_model_name}\"\n",
    "signature_model_weights = \"weights/yolo_signatures.pt\"\n",
    "\n",
    "# paths\n",
    "path_to_results = \"results\"\n",
    "path_to_benchmark = \"data/funsd_benchmark\"\n",
    "path_to_fatura = \"data/fatura\"\n",
    "\n",
    "# benchmark\n",
    "path_to_benchmark_images = os.path.join(path_to_benchmark, \"images\")\n",
    "path_to_gt_benchmark_labeled_images = os.path.join(path_to_benchmark, \"labeled_images\")\n",
    "path_to_gt_benchmark_labels = os.path.join(path_to_benchmark, \"layoutlm_labels\")\n",
    "predicted_benchmark_image_view_path = os.path.join(\n",
    "    path_to_results, f\"benchmark_image_views_{layoutlm_model_name}\"\n",
    ")\n",
    "predicted_benchmark_labels_folder = os.path.join(\n",
    "    path_to_results, f\"benchmark_layoutlm_labels_{layoutlm_model_name}\"\n",
    ")\n",
    "predicted_benchmark_image_view_path_fatura_raw = os.path.join(\n",
    "    path_to_results, f\"benchmark_image_views_{fatura_raw_model_name}\"\n",
    ")\n",
    "predicted_benchmark_labels_folder_fatura_raw = os.path.join(\n",
    "    path_to_results, f\"benchmark_layoutlm_labels_{fatura_raw_model_name}\"\n",
    ")\n",
    "benchmark_images = os.listdir(path_to_benchmark_images)\n",
    "\n",
    "# fatura\n",
    "path_to_fatura_images =  os.path.join(path_to_fatura, \"test_images\")\n",
    "path_to_fatura_benchmark_labeled_images = os.path.join(path_to_fatura, \"test_labeled_images\")\n",
    "path_to_gt_fatura_labels = os.path.join(path_to_fatura, \"test_layoutlm_labels\")\n",
    "predicted_fatura_image_view_path = os.path.join(path_to_results, f\"fatura_image_views_{fatura_raw_model_name}\")\n",
    "predicted_fatura_labels_folder = os.path.join(\n",
    "    path_to_results, f\"fatura_layoutlm_labels_{fatura_raw_model_name}\"\n",
    ")\n",
    "fatura_images = os.listdir(path_to_fatura_images)\n",
    "\n",
    "\n",
    "os.makedirs(path_to_results, exist_ok=True)\n",
    "os.makedirs(predicted_benchmark_image_view_path, exist_ok=True)\n",
    "os.makedirs(predicted_benchmark_labels_folder, exist_ok=True)\n",
    "\n",
    "os.makedirs(predicted_benchmark_image_view_path_fatura_raw, exist_ok=True)\n",
    "os.makedirs(predicted_benchmark_labels_folder_fatura_raw, exist_ok=True)\n",
    "\n",
    "os.makedirs(predicted_fatura_image_view_path, exist_ok=True)\n",
    "os.makedirs(predicted_fatura_labels_folder, exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T09:20:56.868333Z",
     "start_time": "2025-05-14T09:19:09.663694Z"
    }
   },
   "source": [
    "# LayoutLM fine-tuned on SAND\n",
    "sand_inference = AnonymizationInference(\n",
    "    detection_model=detection_model,\n",
    "    recognition_model=recognition_model,\n",
    "    path_to_layoutlm_weights=lm_model_weights,\n",
    "    path_to_signature_weights=signature_model_weights,\n",
    "    label_list=funsd_label_list,\n",
    ")\n",
    "\n",
    "# Benchmark\n",
    "get_layoutlm_predictions(\n",
    "    inference=sand_inference,\n",
    "    images=benchmark_images, \n",
    "    path_to_image=path_to_benchmark_images, \n",
    "    path_to_gt_labeled_images=path_to_gt_benchmark_labeled_images, \n",
    "    labels_saving_path=predicted_benchmark_labels_folder, \n",
    "    image_views_path=predicted_benchmark_image_view_path,\n",
    "    path_to_gt_labels=path_to_gt_benchmark_labels,\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 255/255 [01:42<00:00,  2.49it/s]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T09:22:57.149686Z",
     "start_time": "2025-05-14T09:20:56.885403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LayoutLM fine-tuned solely on FATURA-PII\n",
    "fatura_raw_inference = AnonymizationInference(\n",
    "    detection_model=detection_model,\n",
    "    recognition_model=recognition_model,\n",
    "    path_to_layoutlm_weights=fatura_model_weights,\n",
    "    path_to_signature_weights=signature_model_weights,\n",
    "    label_list=funsd_label_list,\n",
    ")\n",
    "\n",
    "# Benchmark\n",
    "get_layoutlm_predictions(\n",
    "    inference=fatura_raw_inference,\n",
    "    images=benchmark_images, \n",
    "    path_to_image=path_to_benchmark_images, \n",
    "    path_to_gt_labeled_images=path_to_gt_benchmark_labeled_images, \n",
    "    labels_saving_path=predicted_benchmark_labels_folder_fatura_raw, \n",
    "    image_views_path=predicted_benchmark_image_view_path_fatura_raw,\n",
    "    path_to_gt_labels=path_to_gt_benchmark_labels,\n",
    ")\n",
    "\n",
    "# FATURA-PII test\n",
    "get_layoutlm_predictions(\n",
    "    inference=fatura_raw_inference,\n",
    "    images=fatura_images, \n",
    "    path_to_image=path_to_fatura_images, \n",
    "    path_to_gt_labeled_images=path_to_fatura_benchmark_labeled_images, \n",
    "    labels_saving_path=predicted_fatura_labels_folder, \n",
    "    image_views_path=predicted_fatura_image_view_path,\n",
    "    path_to_gt_labels=path_to_gt_fatura_labels,\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 255/255 [01:51<00:00,  2.29it/s]\n",
      "100%|██████████| 19/19 [00:05<00:00,  3.50it/s]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### LayoutLM Fine-tuned on SAND Benchmark Metrics"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T12:07:32.948975Z",
     "start_time": "2025-05-14T12:07:27.585690Z"
    }
   },
   "source": [
    "class_names = [\"full_name\", \"phone_number\", \"address\", \"company_name\", \"email_address\"]\n",
    "sand_metrics_per_documents, _, _ = count_all_layoutlm_metrics(\n",
    "    path_to_gt_benchmark_labels, predicted_benchmark_labels_folder, class_names\n",
    ")\n",
    "sand_metrics_per_documents"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'full_name': defaultdict(float,\n",
       "             {'recall': 0.9664051624813856, 'precision': 0.8909125372042562}),\n",
       " 'phone_number': defaultdict(float,\n",
       "             {'recall': 0.9515424515424513, 'precision': 0.8473034246691538}),\n",
       " 'address': defaultdict(float,\n",
       "             {'recall': 0.9074883776238016, 'precision': 0.897116295060735}),\n",
       " 'company_name': defaultdict(float,\n",
       "             {'recall': 0.7661820906490023, 'precision': 0.7224063803897763}),\n",
       " 'email_address': defaultdict(float,\n",
       "             {'recall': 0.9031746031746032, 'precision': 0.8958333333333334})}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### LayoutLM Fine-tuned solely on FATURA-PII-Train (80 docs) Benchmark and FATURA-PII-Test Metrics"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T09:23:58.590934Z",
     "start_time": "2025-05-14T09:23:56.473940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fatura_metrics_per_documents_benchmark, _, _ = count_all_layoutlm_metrics(\n",
    "    path_to_gt_benchmark_labels, predicted_benchmark_labels_folder_fatura_raw, class_names\n",
    ")\n",
    "fatura_metrics_per_documents_benchmark"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'full_name': defaultdict(float,\n",
       "             {'recall': 0.03384278260834329, 'precision': 0.1935358255451713}),\n",
       " 'phone_number': defaultdict(float,\n",
       "             {'recall': 0.286548849880576, 'precision': 0.4482274482274482}),\n",
       " 'address': defaultdict(float,\n",
       "             {'recall': 0.8520869887298631, 'precision': 0.8778289473027707}),\n",
       " 'company_name': defaultdict(float,\n",
       "             {'recall': 0.3960862396289525, 'precision': 0.3453234217050008}),\n",
       " 'email_address': defaultdict(float,\n",
       "             {'recall': 0.5854166666666667, 'precision': 0.468923611111111})}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T09:24:12.033253Z",
     "start_time": "2025-05-14T09:24:11.962682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fatura_metrics_per_documents_test, _, _ = count_all_layoutlm_metrics(\n",
    "    path_to_gt_fatura_labels, predicted_fatura_labels_folder, class_names\n",
    ")\n",
    "fatura_metrics_per_documents_test"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'full_name': defaultdict(float, {'recall': 0.9375, 'precision': 0.9375}),\n",
       " 'phone_number': defaultdict(float, {'recall': 1.0, 'precision': 0.9875}),\n",
       " 'address': defaultdict(float, {'recall': 1.0, 'precision': 1.0}),\n",
       " 'company_name': defaultdict(float,\n",
       "             {'recall': 1.0, 'precision': 0.9897959183673469}),\n",
       " 'email_address': defaultdict(float,\n",
       "             {'recall': 1.0, 'precision': 0.9583333333333334})}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### STD variance of metrics (Experiment 1 and Experiment 2)"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T13:09:44.514180Z",
     "start_time": "2025-05-14T13:09:44.497893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Trained on SAND\n",
    "print(\"STD metrics for SAND\")\n",
    "count_std([f\"data/std_metrics/sand_metrics{i}.csv\" for i in range(1, 6)])\n",
    "print()\n",
    "print(\"STD metrics for FATURA-PII\")\n",
    "# Trained on FATURA-PII\n",
    "count_std([f\"data/std_metrics/fatura_metrics{i}.csv\" for i in range(1, 6)])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STD metrics for SAND\n",
      "           class  precision_std  recall_std\n",
      "0      full_name       3.880410    1.339171\n",
      "1   phone_number       2.247515    1.148931\n",
      "2        address       2.804857    4.603748\n",
      "3   company_name       3.672424    5.042016\n",
      "4  email_address       7.797683    3.452163\n",
      "\n",
      "STD metrics for FATURA-PII\n",
      "           class  precision_std  recall_std\n",
      "0      full_name      25.661592   11.381131\n",
      "1   phone_number      17.248104   21.166772\n",
      "2        address       4.465766    6.958208\n",
      "3   company_name       8.069297   22.456856\n",
      "4  email_address       8.845300    7.807570\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
